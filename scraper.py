import requests
from bs4 import BeautifulSoup
import json

def scrape():
    url = "https://www.fotbal.cz/souteze/club/club/697be23f-6185-48b9-ba91-66c82b3d81e9"
    # Toto je maskov√°n√≠ za bƒõ≈æn√Ω prohl√≠≈æeƒç:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
    }
    
    print("üöÄ Startuji maskovan√© stahov√°n√≠...")
    
    try:
        session = requests.Session()
        res = session.get(url, headers=headers, timeout=15)
        res.raise_for_status() # Pokud hod√≠ 403, uvid√≠me to v logu
        
        soup = BeautifulSoup(res.content, "html.parser")
        data = {"klub": "SK Slovan Kunratice", "tabulky": []}
        
        for table in soup.find_all("table"):
            rows = []
            for tr in table.find_all("tr"):
                cells = [td.text.strip() for td in tr.find_all(["td", "th"])]
                if cells: rows.append(cells)
            data["tabulky"].append(rows)
            
        print(f"‚úÖ Sta≈æeno {len(data['tabulky'])} tabulek.")
            
    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        data = {"error": str(e), "status": "blocked_or_failed"}

    # V≈ædy zap√≠≈°eme soubor, aby robot nehl√°sil chybu 128
    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print("üíæ Soubor data.json ulo≈æen.")

if __name__ == "__main__":
    scrape()
    
    print(f"Soubor {file_path} byl zaps√°n. Velikost: {os.path.getsize(file_path)} bajt≈Ø")

if __name__ == "__main__":
    scrape()
